#!/usr/bin/env bash
set -euo pipefail

usage() {
  echo "Usage: $0 <input-file-with-presigned-urls | single-presigned-url> <output-dir>"
  exit 1
}

if [ $# -ne 2 ]; then
  usage
fi

INPUT="$1"
OUTPUT_DIR="$2"
mkdir -p "$OUTPUT_DIR"

MAX_CONCURRENT_DOWNLOADS=6
TMP_ARIA2_INPUT="$(mktemp)"
TMP_DIR_LIST="$(mktemp)"

# Handle single URL input
if [[ "$INPUT" =~ ^https?:// ]]; then
  echo "$INPUT" > "$TMP_ARIA2_INPUT.urltmp"
  INPUT="$TMP_ARIA2_INPUT.urltmp"
fi

# Count URLs for warning
URL_COUNT=0
if [[ -f "$INPUT" ]]; then
  # Count non-empty, non-comment lines
  URL_COUNT=$(grep -v -e '^#' -e '^$' "$INPUT" | wc -l)
fi

if (( URL_COUNT > 100000 )); then
  echo "[WARNING] Input file contains $URL_COUNT URLs. Parsing and directory creation may take a long time."
fi

echo "[INFO] Parsing input..."
while IFS= read -r url; do
  [[ -z "$url" || "$url" =~ ^# ]] && continue

  # Extract relative path after domain (before query string)
  path=$(echo "$url" | sed -E 's|https?://[^/]+/([^?]+).*|\1|')
  out_path="$OUTPUT_DIR/$path"
  out_dir=$(dirname "$out_path")

  echo "$out_dir" >> "$TMP_DIR_LIST"

  {
    echo "$url"
    echo "  out=$(basename "$out_path")"
    echo "  dir=$out_dir"
  } >> "$TMP_ARIA2_INPUT"
done < "$INPUT"
echo "[INFO] Input parsed."

echo "[INFO] Creating directories..."
sort -u "$TMP_DIR_LIST" | xargs -n 100 -P 8 mkdir -p
echo "[INFO] Directories created."

rm -f "$TMP_DIR_LIST"

echo "[INFO] Starting downloads..."
aria2c \
  --max-concurrent-downloads=$MAX_CONCURRENT_DOWNLOADS \
  --split=1 \
  --auto-file-renaming=false \
  --allow-overwrite=true \
  --retry-wait=3 \
  --max-tries=3 \
  -i "$TMP_ARIA2_INPUT"
echo "[INFO] Downloads finished."

rm -f "$TMP_ARIA2_INPUT"
[[ -f "$TMP_ARIA2_INPUT.urltmp" ]] && rm -f "$TMP_ARIA2_INPUT.urltmp"
