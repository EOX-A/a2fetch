#!/usr/bin/env bash
set -euo pipefail

usage() {
  echo "Usage: $0 <input-file-with-presigned-urls> <output-dir> [base-url]"
  echo "  or:  $0 <single-presigned-url> <output-dir> [base-url]"
  echo
  echo "If base-url is given, URLs in input file are expected to start with base-url,"
  echo "and output directory structure is created relative to base-url path."
  exit 1
}

if [[ $# -lt 2 || $# -gt 3 ]]; then
  usage
fi

INPUT="$1"
OUTPUT_DIR="$2"
BASE_URL="${3:-}"

if [[ -f "$INPUT" ]]; then
  URL_COUNT=$(grep -cve '^\s*$' -e '^#' "$INPUT" || echo 0)
else
  # Single URL case: just count 1
  URL_COUNT=1
fi

if [[ $URL_COUNT -gt 100000 ]]; then
  echo "[WARNING] Input file contains $URL_COUNT URLs. Parsing and directory creation may take a long time."
fi

if [[ -f "$INPUT" && ! -r "$INPUT" ]]; then
  echo "[ERROR] Input file $INPUT not found or not readable."
  exit 1
fi

mkdir -p "$OUTPUT_DIR"

MAX_CONCURRENT_DOWNLOADS=6
TMP_ARIA2_INPUT="$(mktemp)"
TMP_DIRS="$(mktemp)"

if [[ "$INPUT" =~ ^https?:// ]]; then
  echo "$INPUT" > "$TMP_ARIA2_INPUT.urltmp"
  INPUT="$TMP_ARIA2_INPUT.urltmp"
fi

echo "Parsing URLs and preparing directories..."

# Normalize output dir: remove trailing slash
OUTPUT_DIR="${OUTPUT_DIR%/}"

if [[ -z "$BASE_URL" ]]; then
  # No base URL given, just use full URL paths relative to domain, preserving directory structure

  # We generate the list of directories in TMP_DIRS and aria2 input in TMP_ARIA2_INPUT
  awk -v outdir="$OUTPUT_DIR" -v tmpdirs="$TMP_DIRS" '
  BEGIN {FS="\n"}
  !/^#/ && NF > 0 {
    url=$0;
    # Extract path after domain, before query string
    match(url, /^https?:\/\/[^\/]+\/([^?]+)/, arr);
    if (arr[1] == "") {
      print "[Warning] Cannot parse URL path: " url > "/dev/stderr"
      next
    }
    path=arr[1]
    # Build full output path
    out_path = outdir "/" path
    # Get directory path
    cmd = "dirname \"" out_path "\""
    cmd | getline dir_path
    close(cmd)
    print dir_path > tmpdirs

    print url "\n  out=" substr(out_path, length(dir_path)+2) "\n  dir=" dir_path
  }' "$INPUT" >> "$TMP_ARIA2_INPUT"

else
  # base URL given: URLs in input should start with BASE_URL, paths constructed relative to base URL path

  # Normalize base url: remove trailing slash
  BASE_URL="${BASE_URL%/}"

  awk -v baseurl="$BASE_URL" -v outdir="$OUTPUT_DIR" -v tmpdirs="$TMP_DIRS" '
  BEGIN {FS="\n"}
  !/^#/ && NF > 0 {
    url=$0;
    if (index(url, baseurl) != 1) {
      print "[Warning] URL does not start with base-url, skipping: " url > "/dev/stderr"
      next
    }
    rel_path = substr(url, length(baseurl)+2)  # +2 to skip the slash after baseurl

    # Remove query string if any
    sub(/\?.*$/, "", rel_path)

    # Normalize rel_path to remove leading slash if any
    if (substr(rel_path,1,1)=="/") rel_path=substr(rel_path,2)

    out_path = outdir "/" rel_path

    # Remove trailing slash from output dir and leading slash from rel_path already done above
    # so no double slashes

    # Get directory path
    cmd = "dirname \"" out_path "\""
    cmd | getline dir_path
    close(cmd)
    print dir_path > tmpdirs

    print url "\n  out=" substr(out_path, length(dir_path)+2) "\n  dir=" dir_path
  }' "$INPUT" >> "$TMP_ARIA2_INPUT"
fi

echo "Creating directories..."
sort -u "$TMP_DIRS" | xargs -P 8 -I{} mkdir -p "{}"

rm -f "$TMP_DIRS"

if [[ -f "$TMP_ARIA2_INPUT.urltmp" ]]; then
  rm -f "$TMP_ARIA2_INPUT.urltmp"
fi

echo "Starting downloads with aria2c..."

aria2c --max-concurrent-downloads=$MAX_CONCURRENT_DOWNLOADS --split=1 --auto-file-renaming=false --allow-overwrite=true --retry-wait=3 --max-tries=3 -i "$TMP_ARIA2_INPUT"

rm -f "$TMP_ARIA2_INPUT"

echo "All done."
